# utils/evaluation_metrics.py
# M√≥dulo para c√°lculo de m√©tricas de avalia√ß√£o do modelo
# Autor: Renato Barros
# Email: falecomrenatobarros@gmail.com
# Data: 2025
# Descri√ß√£o: Implementa√ß√£o robusta de m√©tricas ROUGE e BLEU para avalia√ß√£o de modelos de texto

import numpy as np
from evaluate import load
import logging
import torch

logger = logging.getLogger(__name__)

def compute_metrics(eval_pred, tokenizer):
    """
    Calcula m√©tricas de avalia√ß√£o ROUGE e BLEU com tratamento robusto de dados
    
    Esta fun√ß√£o implementa um sistema robusto para calcular m√©tricas de avalia√ß√£o
    de modelos de linguagem, lidando com diferentes formatos de entrada e
    estruturas de dados complexas que podem surgir durante o treinamento.
    
    Args:
        eval_pred: Estrutura contendo predi√ß√µes e labels do modelo
        tokenizer: Tokenizador para decodificar as sequ√™ncias
        
    Returns:
        dict: Dicion√°rio com m√©tricas calculadas (ROUGE-1, ROUGE-2, ROUGE-L, ROUGE-Lsum, BLEU)
    """
    try:
        # Extra√ß√£o segura das predi√ß√µes e labels
        predictions, labels = _extract_predictions_and_labels(eval_pred)
        
        # Convers√£o para formato adequado
        predictions, labels = _convert_to_numpy(predictions, labels)
        
        # Tratamento de estruturas complexas
        predictions = _handle_complex_structures(predictions)
        labels = _handle_complex_structures(labels)
        
        # Verifica√ß√£o e ajuste de dimens√µes
        predictions = _adjust_dimensions(predictions)
        labels = _adjust_dimensions(labels)
        
        logger.info(f"Processando {predictions.shape[0]} exemplos para m√©tricas")
        
        # Decodifica√ß√£o das sequ√™ncias
        decoded_preds, decoded_labels = _decode_sequences(predictions, labels, tokenizer)
        
        # Verifica√ß√£o de dados suficientes
        if len(decoded_preds) == 0:
            logger.warning("Nenhum par v√°lido de predi√ß√£o/label foi decodificado")
            return _get_zero_metrics()
        
        # Log de amostra para debugging
        _log_sample_data(decoded_preds, decoded_labels)
        
        # C√°lculo das m√©tricas
        return _calculate_metrics(decoded_preds, decoded_labels)
        
    except Exception as e:
        logger.error(f"Erro no c√°lculo de m√©tricas: {str(e)}", exc_info=True)
        return _get_zero_metrics_with_error(str(e))

def _extract_predictions_and_labels(eval_pred):
    """
    Extrai predi√ß√µes e labels de diferentes formatos de entrada
    
    Args:
        eval_pred: Estrutura de dados com predi√ß√µes e labels
        
    Returns:
        tuple: (predictions, labels)
    """
    if hasattr(eval_pred, 'predictions') and hasattr(eval_pred, 'label_ids'):
        return eval_pred.predictions, eval_pred.label_ids
    elif isinstance(eval_pred, tuple) and len(eval_pred) == 2:
        return eval_pred
    else:
        raise ValueError(f"Formato de eval_pred n√£o reconhecido: {type(eval_pred)}")

def _convert_to_numpy(predictions, labels):
    """
    Converte tensors para numpy arrays se necess√°rio
    
    Args:
        predictions: Predi√ß√µes do modelo
        labels: Labels verdadeiros
        
    Returns:
        tuple: (predictions, labels) como numpy arrays
    """
    if torch.is_tensor(predictions):
        predictions = predictions.cpu().numpy()
    if torch.is_tensor(labels):
        labels = labels.cpu().numpy()
    
    return predictions, labels

def _handle_complex_structures(data):
    """
    Trata estruturas de dados complexas e irregulares
    
    Args:
        data: Dados a serem processados
        
    Returns:
        np.ndarray: Dados processados
    """
    if isinstance(data, (list, tuple)):
        if len(data) > 0 and hasattr(data[0], 'shape'):
            # Primeira dimens√£o relevante
            data = data[0]
        elif len(data) > 0 and isinstance(data[0], (list, np.ndarray)):
            # Converter lista de listas para array
            try:
                data = np.array(data[0])
            except:
                logger.warning("N√£o foi poss√≠vel converter dados para array")
                return np.array([])
    
    return data

def _adjust_dimensions(data):
    """
    Ajusta dimens√µes dos dados para formato adequado
    
    Args:
        data: Dados a serem ajustados
        
    Returns:
        np.ndarray: Dados com dimens√µes ajustadas
    """
    if not hasattr(data, 'shape'):
        return data
    
    # Se tem 3 dimens√µes (batch, seq_len, vocab_size), aplicar argmax
    if len(data.shape) == 3:
        data = np.argmax(data, axis=-1)
    # Se tem mais de 3 dimens√µes, reformatar
    elif len(data.shape) > 3:
        data = data.reshape(-1, data.shape[-1])
        if data.shape[1] > 1:  # Se ainda tem dimens√£o do vocabul√°rio
            data = np.argmax(data, axis=-1)
    
    # Garantir que √© 2D (batch_size, seq_len)
    if len(data.shape) > 2:
        data = data.reshape(data.shape[0], -1)
    
    return data

def _decode_sequences(predictions, labels, tokenizer):
    """
    Decodifica sequ√™ncias de tokens para texto
    
    Args:
        predictions: Predi√ß√µes tokenizadas
        labels: Labels tokenizados
        tokenizer: Tokenizador para decodifica√ß√£o
        
    Returns:
        tuple: (decoded_predictions, decoded_labels)
    """
    # Convers√£o para formato adequado
    if not isinstance(predictions, np.ndarray):
        predictions = np.array(predictions)
    if not isinstance(labels, np.ndarray):
        labels = np.array(labels)
    
    # Limpeza de labels (remover -100)
    labels_clean = np.where(labels != -100, labels, tokenizer.pad_token_id)
    
    decoded_preds = []
    decoded_labels = []
    
    # Processamento exemplo por exemplo
    for i in range(min(len(predictions), len(labels_clean))):
        try:
            # Decodifica√ß√£o da predi√ß√£o
            pred_text = _decode_single_sequence(predictions[i], tokenizer)
            
            # Decodifica√ß√£o do label
            label_text = _decode_single_sequence(labels_clean[i], tokenizer)
            
            # Adicionar apenas se ambos s√£o v√°lidos
            if pred_text and label_text:
                decoded_preds.append(pred_text)
                decoded_labels.append(label_text)
                
        except Exception as e:
            logger.debug(f"Erro ao decodificar exemplo {i}: {str(e)}")
            continue
    
    return decoded_preds, decoded_labels

def _decode_single_sequence(tokens, tokenizer):
    """
    Decodifica uma √∫nica sequ√™ncia de tokens
    
    Args:
        tokens: Sequ√™ncia de tokens
        tokenizer: Tokenizador
        
    Returns:
        str: Texto decodificado
    """
    if isinstance(tokens, (list, np.ndarray)):
        # Filtrar tokens v√°lidos
        valid_tokens = [int(t) for t in tokens 
                       if isinstance(t, (int, np.integer)) and 0 <= t < tokenizer.vocab_size]
        if len(valid_tokens) > 0:
            return tokenizer.decode(valid_tokens, skip_special_tokens=True).strip()
    
    return ""

def _log_sample_data(decoded_preds, decoded_labels):
    """
    Registra dados de amostra para debugging
    
    Args:
        decoded_preds: Predi√ß√µes decodificadas
        decoded_labels: Labels decodificados
    """
    if len(decoded_preds) > 0:
        logger.info(f"Successfully decoded {len(decoded_preds)} pairs")
        sample_pred = decoded_preds[0][:100] + ('...' if len(decoded_preds[0]) > 100 else '')
        sample_label = decoded_labels[0][:100] + ('...' if len(decoded_labels[0]) > 100 else '')
        logger.info(f"Amostra predi√ß√£o: '{sample_pred}'")
        logger.info(f"Amostra label: '{sample_label}'")

def _calculate_metrics(decoded_preds, decoded_labels):
    """
    Calcula as m√©tricas ROUGE e BLEU
    
    Args:
        decoded_preds: Predi√ß√µes decodificadas
        decoded_labels: Labels decodificados
        
    Returns:
        dict: Dicion√°rio com m√©tricas calculadas
    """
    # Carregamento das m√©tricas
    rouge = load("rouge")
    bleu = load("bleu")
    
    # C√°lculo ROUGE
    rouge_result = rouge.compute(
        predictions=decoded_preds,
        references=decoded_labels,
        use_stemmer=True
    )
    
    # C√°lculo BLEU
    bleu_result = bleu.compute(
        predictions=decoded_preds,
        references=[[label] for label in decoded_labels]
    )
    
    # Compila√ß√£o dos resultados
    result = {
        'rouge1': round(rouge_result['rouge1'], 4),
        'rouge2': round(rouge_result['rouge2'], 4),
        'rougeL': round(rouge_result['rougeL'], 4),
        'rougeLsum': round(rouge_result['rougeLsum'], 4),
        'bleu': round(bleu_result['bleu'], 4)
    }
    
    # Log dos resultados
    logger.info("‚úÖ M√©tricas calculadas com sucesso!")
    logger.info(f"üìä ROUGE-L: {result['rougeL']:.4f}, BLEU: {result['bleu']:.4f}")
    logger.info(f"üìà Pares processados: {len(decoded_preds)}")
    
    return result

def _get_zero_metrics():
    """
    Retorna m√©tricas zeradas para casos de erro
    
    Returns:
        dict: Dicion√°rio com m√©tricas zeradas
    """
    return {
        'rouge1': 0.0,
        'rouge2': 0.0,
        'rougeL': 0.0,
        'rougeLsum': 0.0,
        'bleu': 0.0
    }

def _get_zero_metrics_with_error(error_message):
    """
    Retorna m√©tricas zeradas com mensagem de erro
    
    Args:
        error_message (str): Mensagem de erro
        
    Returns:
        dict: Dicion√°rio com m√©tricas zeradas e erro
    """
    return {
        'rouge1': 0.0,
        'rouge2': 0.0,
        'rougeL': 0.0,
        'rougeLsum': 0.0,
        'bleu': 0.0,
        'error': error_message[:100]  # Limitar tamanho da mensagem
    }