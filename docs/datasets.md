# Datasets e Conformidade com LGPD

Este documento explica como trabalhar com datasets no sistema, incluindo aspectos de privacidade e conformidade com a LGPD.

## üìã Formato dos Dados

### Estrutura Obrigat√≥ria

O sistema espera um arquivo Excel (`.xlsx`) com as seguintes colunas:

| Coluna | Tipo | Obrigat√≥rio | Descri√ß√£o |
|--------|------|-------------|-----------|
| `evento` | String | ‚úÖ | Contexto do evento (ex: "Pinkpop", "Woodstock") |
| `carta` | String | ‚úÖ | Nome da carta (ex: "Dama", "Rei") |
| `tema` | String | ‚úÖ | Tema da interpreta√ß√£o (ex: "Catppuccin", "Tokyo Night") |
| `secao` | String | ‚úÖ | Se√ß√£o espec√≠fica (ex: "Fic√ß√£o cient√≠fica", "Biografia") |
| `texto` | String | ‚úÖ | Texto de interpreta√ß√£o esperado |

### Exemplo de Estrutura

```
evento       | carta | tema         | secao             | texto
-------------|-------|--------------|-------------------|------------------
Pinkpop      | Dama  | Catppuccin   | Fic√ß√£o cient√≠fica | Lorem ipsum dolor sit amet, consectetur adipiscing elit.
Woodstock    | Rei   | Tokyo Night  | Biografia         | Ut at risus vehicula, feugiat nibh a, venenatis felis.
```

## Conformidade com LGPD

### Por que o Dataset n√£o est√° no Reposit√≥rio

O dataset (`database/db_462.xlsx`) **n√£o est√° inclu√≠do** no reposit√≥rio p√∫blico pelos seguintes motivos:

1. **Dados Pessoais**: Pode conter interpreta√ß√µes personalizadas
2. **Propriedade Intelectual**: Conte√∫do autoral espec√≠fico
3. **Conformidade LGPD**: Preven√ß√£o de exposi√ß√£o desnecess√°ria
4. **Controle de Acesso**: Distribui√ß√£o controlada

### Princ√≠pios da LGPD Aplicados

#### 1. Minimiza√ß√£o de Dados
```python
# Apenas colunas necess√°rias s√£o processadas
required_columns = ['evento', 'carta', 'tema', 'secao', 'texto']
df = validate_dataframe(df, required_columns)
```

#### 2. Finalidade Espec√≠fica
- **Finalidade**: Treinamento de modelo de IA
- **Uso**: Gera√ß√£o de interpreta√ß√µes personalizadas
- **Reten√ß√£o**: Dados mantidos apenas durante o treinamento

#### 3. Transpar√™ncia
- Processamento documentado
- C√≥digo fonte dispon√≠vel
- Logs detalhados do treinamento

#### 4. Seguran√ßa
- Dados processados localmente
- Sem transmiss√£o para servi√ßos externos
- Ambiente controlado

## Prepara√ß√£o de Dados

### Valida√ß√£o Autom√°tica

O sistema aplica valida√ß√µes autom√°ticas:

```python
def validate_dataframe(df, required_columns):
    # Verifica√ß√£o de colunas obrigat√≥rias
    if not all(col in df.columns for col in required_columns):
        raise ValueError(f"Colunas necess√°rias: {required_columns}")
    
    # Remo√ß√£o de valores nulos
    df = df.dropna(subset=required_columns)
    
    # Limpeza de texto
    df['texto'] = df['texto'].apply(clean_text)
    
    return df
```

### Limpeza de Dados

```python
def clean_text(text):
    """Remove espa√ßos m√∫ltiplos e caracteres desnecess√°rios"""
    if pd.isna(text):
        return None
    return re.sub(r'\s+', ' ', str(text)).strip()
```

## Configura√ß√£o do Dataset

### Caminho do Arquivo

```yaml
# config/training_config.yaml
dataset_path: "./database/db_462.xlsx"
```

### Divis√£o dos Dados

```yaml
test_size: 0.15      # 15% para valida√ß√£o
random_state: 42     # Seed para reprodutibilidade
```

**Divis√£o estratificada:**
- Mant√©m propor√ß√£o de cartas em treino/valida√ß√£o
- Garante representatividade
- Evita vazamento de dados

## Qualidade dos Dados

### M√©tricas de Qualidade

```python
# Estat√≠sticas geradas automaticamente
print(f"Total de registros: {len(df)}")
print(f"Cartas √∫nicas: {df['carta'].nunique()}")
print(f"Eventos √∫nicos: {df['evento'].nunique()}")
print(f"Comprimento m√©dio: {df['texto'].str.len().mean():.1f}")
print(f"Comprimento m√≠nimo: {df['texto'].str.len().min()}")
print(f"Comprimento m√°ximo: {df['texto'].str.len().max()}")
```

### Distribui√ß√£o Recomendada

| M√©trica | Valor Recomendado | Motivo |
|---------|-------------------|--------|
| **Registros por carta** | 15-30 | Diversidade suficiente |
| **Comprimento m√©dio** | 100-300 caracteres | Qualidade vs. efici√™ncia |
| **Varia√ß√£o de eventos** | 5+ eventos | Generaliza√ß√£o |
| **Varia√ß√£o de temas** | 10+ temas | Cobertura ampla |

## Seguran√ßa dos Dados

### Armazenamento Local

```bash
# Estrutura de pastas
database/
‚îú‚îÄ‚îÄ db_462.xlsx           # Dataset principal (n√£o versionado)
‚îú‚îÄ‚îÄ .gitignore           # Ignora arquivos de dados
‚îî‚îÄ‚îÄ sample_structure.xlsx # Exemplo de estrutura (versionado)
```

### Arquivo .gitignore

```gitignore
# Dados sens√≠veis
database/*.xlsx
database/*.csv
database/*.json
!database/sample_structure.xlsx

# Resultados de treinamento
results/training_log_*.log
results/training_metrics_*.json

# Modelos treinados
model_save/*/
```

## Boas Pr√°ticas

### Anonimiza√ß√£o

Se necess√°rio, voc√™ pode implementar anonimiza√ß√£o dos dados:

- Remo√ß√£o de nomes pr√≥prios
- Substitui√ß√£o de informa√ß√µes pessoais
- Generaliza√ß√£o de dados espec√≠ficos

Isso deve ser feito antes do treinamento, modificando o dataset original conforme suas necessidades de privacidade.

### Backup Seguro

```bash
# Backup com criptografia
gpg --cipher-algo AES256 --compress-algo 2 --symmetric database/db_462.xlsx

# Backup em local seguro
cp database/db_462.xlsx.gpg /backup/secure/
```

### Controle de Vers√£o

```bash
# Versionamento de datasets
database/
‚îú‚îÄ‚îÄ db_462_v1.xlsx
‚îú‚îÄ‚îÄ db_462_v2.xlsx
‚îî‚îÄ‚îÄ db_462_current.xlsx -> db_462_v2.xlsx
```

## üìã Checklist de Conformidade

### Antes do Treinamento

- [ ] Dataset cont√©m apenas dados necess√°rios
- [ ] Dados foram validados e limpos
- [ ] Finalidade do uso est√° documentada
- [ ] Acesso √© controlado e auditado
- [ ] Backup seguro foi criado

### Durante o Treinamento

- [ ] Processamento √© local (sem upload)
- [ ] Logs n√£o exp√µem dados sens√≠veis
- [ ] M√©tricas s√£o agregadas
- [ ] Acesso √© monitorado

### Ap√≥s o Treinamento

- [ ] Dados tempor√°rios s√£o removidos
- [ ] Modelo n√£o "memoriza" dados espec√≠ficos
- [ ] Logs s√£o revisados
- [ ] Documenta√ß√£o √© atualizada

## Atualiza√ß√£o de Datasets

### Processo Seguro

1. **Valida√ß√£o**: Verificar nova estrutura
2. **Backup**: Preservar vers√£o anterior
3. **Teste**: Executar com amostra pequena
4. **Valida√ß√£o**: Confirmar compatibilidade
5. **Aplica√ß√£o**: Usar dataset completo

### Script de Migra√ß√£o

Para migrar datasets entre vers√µes:

1. **Backup**: Sempre fa√ßa backup do dataset original
2. **Valida√ß√£o**: Verifique se a nova estrutura √© compat√≠vel
3. **Teste**: Execute com uma amostra pequena primeiro
4. **Aplica√ß√£o**: Processe o dataset completo
5. **Verifica√ß√£o**: Confirme que o sistema funciona com os novos dados

Use as fun√ß√µes existentes `validate_dataframe` e `clean_text` para garantir consist√™ncia.

## Suporte e D√∫vidas

### Quest√µes Comuns

**Q: Posso usar dados de terceiros?**
A: Apenas com autoriza√ß√£o expressa e conformidade legal.

**Q: Como garantir a qualidade dos dados?**
A: Use as valida√ß√µes autom√°ticas e revise manualmente amostras.

**Q: √â necess√°rio consentimento para uso?**
A: Depende da fonte e finalidade. Consulte assessoria jur√≠dica.

### Contato

Para quest√µes sobre conformidade:
- Consulte assessoria jur√≠dica
- Revise pol√≠tica de privacidade
- Documente todas as decis√µes

---

**Pr√≥ximo**: [Troubleshooting](troubleshooting.md)